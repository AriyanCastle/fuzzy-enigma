(self.webpackChunk_N_E=self.webpackChunk_N_E||[]).push([[991],{5387:function(e,t,r){(window.__NEXT_P=window.__NEXT_P||[]).push(["/kidney",function(){return r(8206)}])},8206:function(e,t,r){"use strict";r.r(t);var a=r(5893),n=r(7294),i=r(2593),o=r(8648);t.default=()=>{let{recording:e,speaking:t,transcribing:r,transcript:c,pauseRecording:s,startRecording:u,stopRecording:l}=(0,i.u)({apiKey:"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",streaming:!0,timeSlice:1e3,whisperConfig:{language:"zh",prompt:"用简体字转录医生与患者在诊疗当中的对话内容"}}),[d,p]=(0,n.useState)(!1),[f,m]=(0,n.useState)(""),[h,y]=(0,n.useState)(""),[g,w]=(0,n.useState)(""),b=e=>{y(t=>t+e)},x=async()=>{if("string"==typeof c.text){let e=await (0,o.gZ)(c.text);m(e),w(e)}else console.error("Error: transcript.text is not a string")},v=async()=>{if("string"==typeof g){let e=await (0,o.J$)(g,b);y(e)}else console.error("Error: editedSummary is not a string")};return(0,a.jsx)("div",{className:"container mx-auto px-4 py-8",children:(0,a.jsxs)("div",{className:"flex flex-col",children:[(0,a.jsx)("div",{className:"flex justify-center mb-6",children:(0,a.jsx)("button",{className:"".concat(d?"bg-red-600":"bg-blue-600"," text-white py-2 px-6 rounded focus:outline-none"),onClick:()=>{d?l():u(),p(!d)},children:d?"停止转录":"转录对话"})}),(0,a.jsxs)("div",{children:[(0,a.jsx)("h3",{className:"font-bold text-lg mb-4",children:"实时对话转录:"}),(0,a.jsx)("div",{className:"bg-blue-100 border border-gray-300 p-4 rounded mb-6 whitespace-pre-wrap",children:c.text}),(0,a.jsx)("button",{className:"bg-green-600 text-white py-2 px-6 rounded focus:outline-none float-right mb-6",onClick:x,children:"摘取重点"})]}),f&&(0,a.jsxs)("div",{children:[(0,a.jsx)("h3",{className:"font-bold text-lg mb-4",children:"对话重点:(请先修改并确认内容，然后才生成现病史)"}),(0,a.jsx)("textarea",{className:"w-full h-28 p-4 border border-gray-300 rounded mb-6 resize-none",value:g,onChange:e=>{w(e.target.value)}}),(0,a.jsx)("button",{className:"bg-green-600 text-white py-2 px-6 rounded focus:outline-none float-right mb-6",onClick:v,children:"生成现病史"})]}),h&&(0,a.jsxs)("div",{children:[(0,a.jsx)("h3",{className:"font-bold text-lg mb-4",children:"现病史:"}),(0,a.jsx)("div",{className:"bg-blue-100 border border-gray-300 p-4 rounded mb-6 whitespace-pre-wrap",children:h})]})]})})}},8648:function(e,t,r){"use strict";r.d(t,{BA:function(){return i},J$:function(){return n},gZ:function(){return a}});let a=async e=>{let t=await fetch("/api/generateSummary",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({conversation:e})});if(!t.ok){let e=await t.text();throw Error("Failed to generate summary: ".concat(e))}let r=await t.json();return r.summary};async function n(e,t){try{let r=await fetch("/api/langchainstream",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({query:e})});if(!r.ok){let e=await r.text();throw console.error("Error response:",e),Error("Failed to generate clinical history")}let a=[],n=r.body.pipeThrough(new TextDecoderStream).getReader();return new Promise((e,r)=>{n.read().then((function r(n){let{done:i,value:o}=n;if(i){e(a.join(""));return}return a.push(o),t(o),this.read().then(r.bind(this))}).bind(n)).catch(e=>{console.error("Error in fetchClinicalHistoryStream:",e),r(e)})})}catch(e){throw console.error("Error in fetchClinicalHistoryStream:",e),e}}async function i(e){try{let t=await fetch("/api/generateClinicalHistory",{method:"POST",headers:{"Content-Type":"application/json"},body:JSON.stringify({summary:e})});if(!t.ok){let e=await t.text();throw console.error("Error response:",e),Error("Failed to generate clinical history")}let r=await t.json();return r.history}catch(e){throw console.error("Error in fetchClinicalHistory:",e),e}}},2593:function(e,t,r){"use strict";r.d(t,{u:function(){return u}});var a=r(7294),n=(e,t,r,n)=>{let i=(0,a.useMemo)(()=>{let e=[];return Array.isArray(t)&&(e=[...e,...t]),Array.isArray(r)&&(e=[...e,...r]),Array.isArray(n)&&(e=[...e,...n]),e},[n,t,r]);return(0,a.useEffect)(()=>((async()=>{try{await e()}catch(e){"function"==typeof r?r(e):console.info(e)}})(),()=>{"function"==typeof t&&t()}),i)},i=(e,t,r)=>{let n=(0,a.useMemo)(()=>{let e=[];return Array.isArray(t)&&(e=[...e,...t]),Array.isArray(r)&&(e=[...e,...r]),e},[t,r]);return(0,a.useMemo)(()=>async(...r)=>{try{return await e(...r)}catch(e){"function"==typeof t?t(e):console.error("useMemo",e)}},n)},o={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},c={stop:void 0},s={blob:void 0,text:void 0},u=e=>{let{apiKey:t,autoStart:u,autoTranscribe:l,mode:d,nonStop:p,removeSilence:f,stopTimeout:m,streaming:h,timeSlice:y,whisperConfig:g,onDataAvailable:w,onTranscribe:b}={...o,...e};if(!t&&!b)throw Error("apiKey is required if onTranscribe is not provided");let x=(0,a.useRef)([]),v=(0,a.useRef)(),S=(0,a.useRef)(),T=(0,a.useRef)(),k=(0,a.useRef)(),_=(0,a.useRef)(c),[j,E]=(0,a.useState)(!1),[N,C]=(0,a.useState)(!1),[R,A]=(0,a.useState)(!1),[B,F]=(0,a.useState)(s);(0,a.useEffect)(()=>()=>{x.current&&(x.current=[]),v.current&&(v.current.flush(),v.current=void 0),T.current&&(T.current.destroy(),T.current=void 0),G("stop"),S.current&&(S.current.off("speaking",K),S.current.off("stopped_speaking",$)),k.current&&(k.current.getTracks().forEach(e=>e.stop()),k.current=void 0)},[]),n(async()=>{u&&await H()},[u]);let P=async()=>{await H()},O=async()=>{await z()},J=async()=>{await X()},H=async()=>{try{if(k.current||await M(),k.current){if(!T.current){let{default:{RecordRTCPromisesHandler:e,StereoAudioRecorder:t}}=await Promise.all([r.e(153),r.e(454)]).then(r.t.bind(r,5212,19));T.current=new e(k.current,{mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:t,sampleRate:44100,timeSlice:h?y:void 0,type:"audio",ondataavailable:l&&h?L:void 0})}if(!v.current){let{Mp3Encoder:e}=await r.e(644).then(r.t.bind(r,5644,19));v.current=new e(1,44100,96)}let e=await T.current.getState();("inactive"===e||"stopped"===e)&&await T.current.startRecording(),"paused"===e&&await T.current.resumeRecording(),p&&D("stop"),E(!0)}}catch{}},M=async()=>{try{if(k.current&&k.current.getTracks().forEach(e=>e.stop()),k.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!S.current){let{default:e}=await r.e(233).then(r.t.bind(r,8233,19));S.current=e(k.current,{interval:100,play:!1}),S.current.on("speaking",K),S.current.on("stopped_speaking",$)}}catch{}},D=e=>{_.current[e]||(_.current[e]=setTimeout(X,m))},K=()=>{C(!0),G("stop")},$=()=>{C(!1),p&&D("stop")},z=async()=>{try{T.current&&(await T.current.getState()==="recording"&&await T.current.pauseRecording(),G("stop"),E(!1))}catch{}},X=async()=>{try{if(T.current){let e=await T.current.getState();if(("recording"===e||"paused"===e)&&await T.current.stopRecording(),q(),G("stop"),E(!1),l)await I();else{let e=await T.current.getBlob();F({blob:e})}await T.current.destroy(),x.current=[],v.current&&(v.current.flush(),v.current=void 0),T.current=void 0}}catch{}},q=()=>{S.current&&(S.current.off("speaking",K),S.current.off("stopped_speaking",$),S.current=void 0),k.current&&(k.current.getTracks().forEach(e=>e.stop()),k.current=void 0)},G=e=>{_.current[e]&&(clearTimeout(_.current[e]),_.current[e]=void 0)},I=async()=>{try{if(v.current&&T.current&&await T.current.getState()==="stopped"){A(!0);let e=await T.current.getBlob();if(f){let{createFFmpeg:t}=await r.e(45).then(r.t.bind(r,5045,19)),a=t({mainName:"main",corePath:"https://unpkg.com/@ffmpeg/core-st@0.11.1/dist/ffmpeg-core.js",log:!0});a.isLoaded()||await a.load();let n=await e.arrayBuffer();a.FS("writeFile","in.wav",new Uint8Array(n)),await a.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af","silenceremove=start_periods=1:stop_periods=-1:start_threshold=-30dB:stop_threshold=-30dB:start_silence=2:stop_silence=2","out.mp3");let i=a.FS("readFile","out.mp3");if(i.length<=225){a.exit(),F({blob:e}),A(!1);return}e=new Blob([i.buffer],{type:"audio/mpeg"}),a.exit()}else{let t=await e.arrayBuffer(),r=v.current.encodeBuffer(new Int16Array(t));e=new Blob([r],{type:"audio/mpeg"})}if("function"==typeof b){let t=await b(e);F(t)}else{let t=new File([e],"speech.mp3",{type:"audio/mpeg"}),r=await U(t);F({blob:e,text:r})}A(!1)}}catch{A(!1)}},L=async e=>{try{if(h&&T.current){if(w?.(e),v.current){let t=await e.arrayBuffer(),r=v.current.encodeBuffer(new Int16Array(t)),a=new Blob([r],{type:"audio/mpeg"});x.current.push(a)}if(await T.current.getState()==="recording"){let e=new Blob(x.current,{type:"audio/mpeg"}),t=new File([e],"speech.mp3",{type:"audio/mpeg"}),r=await U(t);r&&F(e=>({...e,text:r}))}}}catch{}},U=i(async e=>{let a=new FormData;a.append("file",e),a.append("model","whisper-1"),"transcriptions"===d&&a.append("language",g?.language??"en"),g?.prompt&&a.append("prompt",g.prompt),g?.response_format&&a.append("response_format",g.response_format),g?.temperature&&a.append("temperature",`${g.temperature}`);let n={};n["Content-Type"]="multipart/form-data",t&&(n.Authorization=`Bearer ${t}`);let{default:i}=await r.e(856).then(r.bind(r,2856));return(await i.post("https://api.openai.com/v1/audio/"+d,a,{headers:n})).data.text},[t,d,g]);return{recording:j,speaking:N,transcribing:R,transcript:B,pauseRecording:O,startRecording:P,stopRecording:J}}}},function(e){e.O(0,[774,888,179],function(){return e(e.s=5387)}),_N_E=e.O()}]);